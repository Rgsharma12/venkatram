{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "azuredatafactoryaccount"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/ds_empdata')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_blobstorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "employeedata.csv",
						"folderPath": "venkatcontainer",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "empid",
						"type": "String"
					},
					{
						"name": "name",
						"type": "String"
					},
					{
						"name": "gender",
						"type": "String"
					},
					{
						"name": "salary",
						"type": "String"
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_employeedataset')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_blobstorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "emp123.csv",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "empid",
						"type": "String"
					},
					{
						"name": "name",
						"type": "String"
					},
					{
						"name": "country",
						"type": "String"
					},
					{
						"name": "department  ",
						"type": "String"
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_output')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_blobstorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "files",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "deptid",
						"type": "String"
					},
					{
						"name": "Total Employees",
						"type": "String"
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_pivot123')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_blobstorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"folderPath": "files",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_pivotdata')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_blobstorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "EmpGender.csv",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "EmpId",
						"type": "String"
					},
					{
						"name": "EmpName",
						"type": "String"
					},
					{
						"name": "EmpSalary",
						"type": "String"
					},
					{
						"name": "Gender",
						"type": "String"
					},
					{
						"name": "department",
						"type": "String"
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_scd1')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ls_blobstorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "emp123.csv",
						"container": "adfdemo"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "empid",
						"type": "String"
					},
					{
						"name": "name",
						"type": "String"
					},
					{
						"name": "country",
						"type": "String"
					},
					{
						"name": "department  ",
						"type": "String"
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ds_sqlscd1')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "empid",
						"type": "int",
						"precision": 10
					},
					{
						"name": "name",
						"type": "varchar"
					},
					{
						"name": "country",
						"type": "varchar"
					},
					{
						"name": "department",
						"type": "int",
						"precision": 10
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "emp_tbl"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/ls_sqldb')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [
					{
						"name": "empid",
						"type": "int",
						"precision": 10
					},
					{
						"name": "name",
						"type": "varchar"
					},
					{
						"name": "gender",
						"type": "varchar"
					},
					{
						"name": "salary",
						"type": "int",
						"precision": 10
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "employee"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline4_copydata')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Lookup1",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "7.00:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"sqlReaderQuery": "select table_schema,table_name from information_schema.tables where Table_type='Base Table' and Table_schema='DBO'",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"dataset": {
								"referenceName": "AzureSqlTable3",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Lookup1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Lookup1').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Copy data1",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "7.00:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "AzureSqlSource",
											"queryTimeout": "02:00:00",
											"partitionOption": "None"
										},
										"sink": {
											"type": "DelimitedTextSink",
											"storeSettings": {
												"type": "AzureBlobStorageWriteSettings"
											},
											"formatSettings": {
												"type": "DelimitedTextWriteSettings",
												"quoteAllText": true,
												"fileExtension": ".txt"
											}
										},
										"enableStaging": false,
										"translator": {
											"type": "TabularTranslator",
											"typeConversion": true,
											"typeConversionSettings": {
												"allowDataTruncation": true,
												"treatBooleanAsNumber": false
											}
										}
									},
									"inputs": [
										{
											"referenceName": "AzureSqlTable2",
											"type": "DatasetReference",
											"parameters": {
												"table": {
													"value": "@item().table_name",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "DelimitedText1",
											"type": "DatasetReference",
											"parameters": {
												"FileName": {
													"value": "@item().table_name",
													"type": "Expression"
												}
											}
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_empdata",
								"type": "DatasetReference"
							},
							"name": "empsource"
						},
						{
							"dataset": {
								"referenceName": "ls_sqldb",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "derivedColumn2"
						},
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> empsource",
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source1",
						"empsource derive(hashcsv = sha2(256, columns())) ~> derivedColumn1",
						"source1 derive(hashsql = sha2(256, columns())) ~> derivedColumn2",
						"derivedColumn1, derivedColumn2 exists(empsource@empid == source1@empid,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ds_empdata')]",
				"[concat(variables('factoryId'), '/datasets/ls_sqldb')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow10')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText15",
								"type": "DatasetReference"
							},
							"name": "employees"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText16",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedText17",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> employees",
						"source(output(",
						"          deptid as integer,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"employees aggregate(groupBy(deptid),",
						"     {Total Employees} = count(empid)) ~> aggregate1",
						"aggregate1, source1 join(aggregate1@deptid == source1@deptid,",
						"     joinType:'inner',",
						"     broadcast: 'auto')~> join1",
						"join1 select(mapColumn(",
						"          {Total Employees},",
						"          deptname",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['Aggregate_join_data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow11')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText18",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink2"
						},
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink3"
						},
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink4"
						}
					],
					"transformations": [
						{
							"name": "split1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          salary as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 split(equals(deptid, 10),",
						"     equals(deptid, 20),",
						"     equals(deptid, 30),",
						"     disjoint: false) ~> split1@(ITEmployees, HREmployees, PayRollEmployees, OtherEmployees)",
						"split1@ITEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['ITEmployees_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"split1@HREmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['HREmployees_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2",
						"split1@PayRollEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['PayRollEmployees_data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink3",
						"split1@OtherEmployees sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['OtherEmployees_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink4"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ds_output')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow12')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText19",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "derivedColumn2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 derive(country = upper(country)) ~> derivedColumn1",
						"derivedColumn1 derive(NewCountryColumn = iif(isNull(country), 'UnKnown', 'india')) ~> derivedColumn2",
						"derivedColumn2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['Derived_data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ds_output')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow13')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText20",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText21",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          department as integer,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1, source2 exists(deptid == department,",
						"     negate:false,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['Exists_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ds_output')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow13_NonExists')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText20",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText21",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          department as integer,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1, source2 exists(deptid == department,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['NonExists_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ds_output')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText31",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          salary as integer,",
						"          department as integer,",
						"          gender as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 alterRow(deleteIf(department==40),",
						"     updateIf(department==10)) ~> alterRow1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['empid'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          empid,",
						"          name = empname,",
						"          gender,",
						"          salary",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14_LookupDta')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText25",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText26",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "lookup1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          salary as integer,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          deptid as integer,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1, source2 lookup(source1@deptid == source2@deptid,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['Lookup_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ds_output')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14_NewBranch')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText27",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText28",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          salary as string,",
						"          deptid as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          deptid as string,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1 aggregate(groupBy(deptid),",
						"     TotalEmployess = count(empid)) ~> aggregate1",
						"source1, source2 join(source1@deptid == source2@deptid,",
						"     joinType:'inner',",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['NewBranchAgg_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['NewBranchJoin_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ds_output')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14_SurrogateKey')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText29",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 keyGenerate(output(Empid as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 select(mapColumn(",
						"          Empid,",
						"          name,",
						"          country,",
						"          department",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['SurrogateKey_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ds_output')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14_select')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText27",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          salary as string,",
						"          deptid as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 select(mapColumn(",
						"          {Employee Name} = empname,",
						"          {Employee Id} = empid,",
						"          {Employees salary} = salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['Select_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/ds_output')]"
			]
		}
	]
}