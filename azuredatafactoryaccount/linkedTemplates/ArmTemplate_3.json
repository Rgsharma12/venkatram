{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "azuredatafactoryaccount"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/dataflow13')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText20",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText21",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          department as integer,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1, source2 exists(deptid == department,",
						"     negate:false,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['Exists_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow13_NonExists')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText20",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText21",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          department as integer,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1, source2 exists(deptid == department,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['NonExists_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText31",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          salary as integer,",
						"          department as integer,",
						"          gender as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 alterRow(deleteIf(department==40),",
						"     updateIf(department==10)) ~> alterRow1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:true,",
						"     upsertable:false,",
						"     keys:['empid'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          empid,",
						"          name = empname,",
						"          gender,",
						"          salary",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14_LookupDta')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText25",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText26",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "lookup1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          salary as integer,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          deptid as integer,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1, source2 lookup(source1@deptid == source2@deptid,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['Lookup_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14_NewBranch')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText27",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText28",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						},
						{
							"name": "join1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          salary as string,",
						"          deptid as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          deptid as string,",
						"          deptname as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1 aggregate(groupBy(deptid),",
						"     TotalEmployess = count(empid)) ~> aggregate1",
						"source1, source2 join(source1@deptid == source2@deptid,",
						"     joinType:'inner',",
						"     broadcast: 'auto')~> join1",
						"join1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['NewBranchAgg_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['NewBranchJoin_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14_SurrogateKey')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText29",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "surrogateKey1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          name as string,",
						"          country as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 keyGenerate(output(Empid as long),",
						"     startAt: 1L,",
						"     stepValue: 1L) ~> surrogateKey1",
						"surrogateKey1 select(mapColumn(",
						"          Empid,",
						"          name,",
						"          country,",
						"          department",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['SurrogateKey_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14_select')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText27",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          empname as string,",
						"          salary as string,",
						"          deptid as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 select(mapColumn(",
						"          {Employee Name} = empname,",
						"          {Employee Id} = empid,",
						"          {Employees salary} = salary",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['Select_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14_sort')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText27",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          salary as integer,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 sort(desc(salary, true)) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['sort_data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14_union')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText22",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText23",
								"type": "DatasetReference"
							},
							"name": "source2"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText24",
								"type": "DatasetReference"
							},
							"name": "source3"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "union1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          salary as integer,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          salary as integer,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          salary as integer,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source3",
						"source1, source2, source3 union(byName: true)~> union1",
						"union1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['AllEmployees_data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow14_window')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText30",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "window1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          gender as string,",
						"          country as string,",
						"          salary as integer,",
						"          department as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 window(over(department),",
						"     asc(salary, true),",
						"     Avgsalary = avg(salary)) ~> window1",
						"window1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['WindowsData.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow15_DenseRank')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText32",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "rank1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          salary as integer,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 rank(desc(salary, true),",
						"     output({Dense Ranking} as long),",
						"     dense: true) ~> rank1",
						"rank1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['DenseRanking_data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow15_Flattern')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Json1",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as string,",
						"          name as string,",
						"          skills as string[],",
						"          Address as (state as string, country as string, {zip-code} as string),",
						"          contact as (phone as string, mail as string)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'singleDocument') ~> source1",
						"source1 foldDown(unroll(skills),",
						"     mapColumn(",
						"          id,",
						"          name,",
						"          skills",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"flatten1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['FlattenSkills.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow15_RTS39')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText33",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "derivedColumn2"
						},
						{
							"name": "exists1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source2",
						"source1 derive(HashColumn = sha2(256, columns())) ~> derivedColumn1",
						"source2 derive(hashing = sha2(256, columns())) ~> derivedColumn2",
						"derivedColumn1, derivedColumn2 exists(HashColumn == hashing,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists1",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as integer,",
						"          name as string,",
						"          gender as string,",
						"          salary as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow15_parse')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "AzureSqlTable4",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Json2",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "parse1"
						},
						{
							"name": "parse2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empID as integer,",
						"          empName as string,",
						"          skills as string,",
						"          address as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     isolationLevel: 'READ_UNCOMMITTED',",
						"     format: 'table') ~> source1",
						"source1 parse(ParseSkills = skills ? (skill1 as string,",
						"          skill2 as string,",
						"          skill3 as string),",
						"     format: 'delimited',",
						"     columnNamesAsHeader: false,",
						"     columnDelimiter: '|',",
						"     nullValue: '') ~> parse1",
						"parse1 parse(ParseAddress = address ? (city as string,",
						"          state as string),",
						"     format: 'delimited',",
						"     columnNamesAsHeader: false,",
						"     columnDelimiter: '|',",
						"     nullValue: '') ~> parse2",
						"parse2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['employees.json'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          empID,",
						"          empName,",
						"          ParseSkills,",
						"          ParseAddress",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow15_rank')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText32",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "rank1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          salary as integer,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 rank(desc(salary, true),",
						"     output(Ranking as long)) ~> rank1",
						"rank1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          deptid as string,",
						"          {Total Employees} as string",
						"     ),",
						"     partitionFileNames:['Ranking_data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow2')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_scd1",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_Sqlscdtype1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          {department  } as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 alterRow(upsertIf(1==1)) ~> alterRow1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as integer,",
						"          name as string,",
						"          country as string,",
						"          department as integer",
						"     ),",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:false,",
						"     upsertable:true,",
						"     keys:['empid'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          empid,",
						"          name,",
						"          country,",
						"          department = {department  }",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow3')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_pivotdata",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_pivot123",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "pivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          EmpId as string,",
						"          EmpName as string,",
						"          EmpSalary as string,",
						"          Gender as string,",
						"          department as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 pivot(groupBy(department),",
						"     pivotBy(Gender),",
						"     {} = count(EmpId),",
						"     columnNaming: '$N$V',",
						"     lateral: true) ~> pivot1",
						"pivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:['EmpPivotData.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow4')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText2",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedText3",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "unpivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          po as string,",
						"          vendor as string,",
						"          apple as string,",
						"          Banana as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 unpivot(output(",
						"          fruits as string,",
						"          amount as string",
						"     ),",
						"     ungroupBy(po,",
						"          vendor),",
						"     lateral: true,",
						"     ignoreNullPivots: false) ~> unpivot1",
						"unpivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          department as string,",
						"          {'Female'} as string,",
						"          {'Male'} as string",
						"     ),",
						"     partitionFileNames:['Emp_Unpivot_data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow5')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText4",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedText5",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "unpivot1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          department as string,",
						"          {'Female'} as string,",
						"          {'Male'} as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 unpivot(output(",
						"          Gender as string,",
						"          TotalEmployees as string",
						"     ),",
						"     ungroupBy(department),",
						"     lateral: true,",
						"     ignoreNullPivots: false) ~> unpivot1",
						"unpivot1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          department as string,",
						"          {'Female'} as string,",
						"          {'Male'} as string",
						"     ),",
						"     partitionFileNames:['Emp_Pivot_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow6')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DelimitedText6",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText7",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "DelimitedText8",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "lookup1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          empname as string,",
						"          salary as integer,",
						"          deptid as integer",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          deptid as integer,",
						"          deptname as string,",
						"          deptloc as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1, source2 lookup(source1@deptid == source2@deptid,",
						"     multiple: false,",
						"     pickup: 'any',",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          department as string,",
						"          {'Female'} as string,",
						"          {'Male'} as string",
						"     ),",
						"     partitionFileNames:['Look_Up_Data.csv'],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		}
	]
}